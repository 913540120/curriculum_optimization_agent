"""é¡¹ç›®åè°ƒå®˜ - åŸ¹å…»æ–¹æ¡ˆä¼˜åŒ–æµç¨‹æ€»æŒ‡æŒ¥"""

from typing import Dict, List, Any, Optional
import asyncio
from datetime import datetime

from .base_agent import BaseAgent
from ..utils.conflict_detector import ConflictDetector
from ..utils.convergence_checker import ConvergenceChecker
from ..models import CurriculumOptimizationState, OptimizationConfig, DEFAULT_OPTIMIZATION_CONFIG

class ProjectCoordinator(BaseAgent):
    """é¡¹ç›®åè°ƒå®˜ - ä¼˜åŒ–æµç¨‹æ€»æŒ‡æŒ¥"""
    
    def __init__(self, openai_api_key: str, config: Optional[OptimizationConfig] = None):
        """
        åˆå§‹åŒ–é¡¹ç›®åè°ƒå®˜
        
        Args:
            openai_api_key: OpenAI APIå¯†é’¥
            config: ä¼˜åŒ–é…ç½®
        """
        super().__init__(
            agent_name="é¡¹ç›®åè°ƒå®˜",
            agent_type="project_coordinator", 
            openai_api_key=openai_api_key
        )
        
        self.config = config or DEFAULT_OPTIMIZATION_CONFIG
        self.conflict_detector = ConflictDetector()
        self.convergence_checker = ConvergenceChecker(self.config["convergence_threshold"])
        
        # åˆå§‹åŒ–åˆ©ç›Šç›¸å…³è€…æ™ºèƒ½ä½“ï¼ˆå»¶è¿Ÿåˆå§‹åŒ–ï¼‰
        self.stakeholder_agents = {}
        self._initialize_stakeholder_agents(openai_api_key)
        
        print(f"ğŸ© {self.agent_name} åˆå§‹åŒ–å®Œæˆï¼Œé…ç½®: {self.config}")

    def _initialize_stakeholder_agents(self, openai_api_key: str):
        """åˆå§‹åŒ–åˆ©ç›Šç›¸å…³è€…æ™ºèƒ½ä½“"""
        try:
            from .academic_affairs_agent import AcademicAffairsAgent
            from .hr_recruiter_agent import HRRecruiterAgent
            from .industry_expert_agent import IndustryExpertAgent
            from .student_representative_agent import StudentRepresentativeAgent
            from .faculty_representative_agent import FacultyRepresentativeAgent
            
            self.stakeholder_agents = {
                "academic_affairs": AcademicAffairsAgent(openai_api_key),
                "hr_recruiter": HRRecruiterAgent(openai_api_key),
                "industry_expert": IndustryExpertAgent(openai_api_key),
                "student_representative": StudentRepresentativeAgent(openai_api_key),
                "faculty_representative": FacultyRepresentativeAgent(openai_api_key)
            }
        except ImportError:
            print("âš ï¸ éƒ¨åˆ†æ™ºèƒ½ä½“æ¨¡å—å°šæœªå®ç°ï¼Œä½¿ç”¨æ¨¡æ‹Ÿæ™ºèƒ½ä½“")
            # åˆ›å»ºæ¨¡æ‹Ÿæ™ºèƒ½ä½“
            self.stakeholder_agents = {
                "academic_affairs": MockAgent("æ•™åŠ¡å¤„ä»£è¡¨", "academic_affairs"),
                "hr_recruiter": MockAgent("HRæ‹›è˜ä»£è¡¨", "hr_recruiter"),
                "industry_expert": MockAgent("è¡Œä¸šä¸“å®¶", "industry_expert"),
                "student_representative": MockAgent("å­¦ç”Ÿä»£è¡¨", "student_representative"),
                "faculty_representative": MockAgent("æ•™å¸ˆä»£è¡¨", "faculty_representative")
            }

    def get_system_prompt(self) -> str:
        """è·å–ç³»ç»Ÿæç¤ºè¯"""
        return """
        ä½ æ˜¯åŸ¹å…»æ–¹æ¡ˆæ™ºèƒ½ä¼˜åŒ–å¹³å°çš„é¡¹ç›®åè°ƒå®˜ï¼Œè´Ÿè´£ç®¡ç†æ•´ä¸ªä¼˜åŒ–æµç¨‹ã€‚
        
        ä½ çš„èŒè´£åŒ…æ‹¬ï¼š
        1. åè°ƒå„åˆ©ç›Šç›¸å…³è€…çš„åˆ†æå·¥ä½œ
        2. ç®¡ç†å¤šè½®ä¼˜åŒ–å¾ªç¯
        3. æ£€æµ‹å’Œå¤„ç†å†²çª
        4. åˆ¤æ–­æ”¶æ•›æ¡ä»¶
        5. ç”Ÿæˆæœ€ç»ˆä¼˜åŒ–æŠ¥å‘Š
        
        è¯·ç¡®ä¿ä¼˜åŒ–è¿‡ç¨‹å…¬å¹³ã€é«˜æ•ˆã€æ”¶æ•›ã€‚
        """

    def analyze(self, curriculum: Dict[str, Any], **kwargs) -> Dict[str, Any]:
        """åè°ƒæ•´ä¸ªä¼˜åŒ–åˆ†æè¿‡ç¨‹"""
        # é¡¹ç›®åè°ƒå®˜ä¸ç›´æ¥åˆ†æï¼Œè€Œæ˜¯åè°ƒå…¶ä»–æ™ºèƒ½ä½“
        return {"message": "é¡¹ç›®åè°ƒå®˜è´Ÿè´£åè°ƒï¼Œè¯·ä½¿ç”¨run_optimizationæ–¹æ³•"}

    def run_optimization(
        self, 
        initial_curriculum: Dict[str, Any],
        major_name: str,
        target_positions: List[str]
    ) -> CurriculumOptimizationState:
        """
        è¿è¡Œå®Œæ•´çš„ä¼˜åŒ–æµç¨‹
        
        Args:
            initial_curriculum: åˆå§‹åŸ¹å…»æ–¹æ¡ˆ
            major_name: ä¸“ä¸šåç§°
            target_positions: ç›®æ ‡å²—ä½ç¾¤
            
        Returns:
            CurriculumOptimizationState: æœ€ç»ˆä¼˜åŒ–çŠ¶æ€
        """
        print(f"ğŸš€ å¯åŠ¨åŸ¹å…»æ–¹æ¡ˆä¼˜åŒ–æµç¨‹")
        print(f"ğŸ“‹ ä¸“ä¸š: {major_name}")
        print(f"ğŸ¯ ç›®æ ‡å²—ä½: {', '.join(target_positions)}")
        
        # åˆ›å»ºåˆå§‹ä¼˜åŒ–çŠ¶æ€
        from ..models import create_optimization_state
        optimization_state = create_optimization_state(
            major_name=major_name,
            target_positions=target_positions,
            original_curriculum=initial_curriculum,
            config=self.config
        )
        
        optimization_state["status"] = "optimizing"
        start_time = datetime.now()
        
        try:
            # å¤šè½®ä¼˜åŒ–å¾ªç¯
            for round_num in range(1, self.config["max_rounds"] + 1):
                print(f"\n{'='*50}")
                print(f"ğŸ”„ ç¬¬ {round_num}/{self.config['max_rounds']} è½®ä¼˜åŒ–")
                print(f"{'='*50}")
                
                optimization_state["optimization_round"] = round_num
                optimization_state["updated_at"] = datetime.now().isoformat()
                
                # æ‰§è¡Œå•è½®ä¼˜åŒ–
                round_result = self._run_single_round(optimization_state)
                
                # æ›´æ–°ä¼˜åŒ–çŠ¶æ€
                optimization_state.update(round_result)
                
                # æ£€æŸ¥æ”¶æ•›æ¡ä»¶
                if self.convergence_checker.is_converged(optimization_state):
                    print(f"âœ… ç¬¬ {round_num} è½®è¾¾åˆ°æ”¶æ•›æ¡ä»¶ï¼Œä¼˜åŒ–å®Œæˆ")
                    optimization_state["is_consensus_reached"] = True
                    break
                
                # æ£€æŸ¥æ˜¯å¦è¾¾åˆ°æœ€å¤§è½®æ•°
                if round_num >= self.config["max_rounds"]:
                    print(f"â° è¾¾åˆ°æœ€å¤§è½®æ•° {self.config['max_rounds']}ï¼Œç»“æŸä¼˜åŒ–")
                    break
            
            # è®¡ç®—æ€»è€—æ—¶
            end_time = datetime.now()
            optimization_state["optimization_duration"] = (end_time - start_time).total_seconds()
            optimization_state["status"] = "converged" if optimization_state["is_consensus_reached"] else "completed"
            
            print(f"\nğŸ‰ ä¼˜åŒ–æµç¨‹å®Œæˆ")
            print(f"â±ï¸ æ€»è€—æ—¶: {optimization_state['optimization_duration']:.1f}ç§’")
            print(f"ğŸ”„ æ€»è½®æ•°: {optimization_state['optimization_round']}")
            
            return optimization_state
            
        except Exception as e:
            print(f"âŒ ä¼˜åŒ–è¿‡ç¨‹å‡ºç°é”™è¯¯: {str(e)}")
            optimization_state["status"] = "error"
            return optimization_state

    def _run_single_round(self, state: CurriculumOptimizationState) -> Dict[str, Any]:
        """è¿è¡Œå•è½®ä¼˜åŒ–"""
        round_num = state["optimization_round"]
        current_curriculum = state["current_curriculum"]
        target_positions = state["target_positions"]
        
        print(f"ğŸ“Š å¼€å§‹ç¬¬ {round_num} è½®åˆ†æ...")
        
        # Step 1: å¹¶è¡Œæ”¶é›†å„åˆ©ç›Šç›¸å…³è€…çš„å»ºè®®
        stakeholder_suggestions = self._collect_stakeholder_feedback(
            current_curriculum, target_positions
        )
        
        # Step 2: å†²çªæ£€æµ‹
        all_suggestions = []
        for agent_type, suggestions in stakeholder_suggestions.items():
            all_suggestions.extend(suggestions)
        
        conflicts = self.conflict_detector.detect_conflicts(all_suggestions)
        
        # Step 3: å†²çªè°ƒè§£ï¼ˆç®€åŒ–å®ç°ï¼‰
        mediated_solutions = self._mediate_conflicts(conflicts, all_suggestions)
        
        # Step 4: åº”ç”¨ä¼˜åŒ–å»ºè®®ï¼ˆç®€åŒ–å®ç°ï¼‰
        optimized_curriculum = self._apply_optimizations(
            current_curriculum, mediated_solutions
        )
        
        # Step 5: è¯„ä¼°æ»¡æ„åº¦
        satisfaction_scores = self._evaluate_stakeholder_satisfaction(stakeholder_suggestions)
        
        # æ›´æ–°ç»“æœ
        round_result = {
            "stakeholder_feedback": stakeholder_suggestions,
            "conflict_analysis": conflicts,
            "mediated_solutions": mediated_solutions,
            "current_curriculum": optimized_curriculum,
            "stakeholder_satisfaction": satisfaction_scores,
            "optimization_log": state["optimization_log"] + [{
                "round": round_num,
                "suggestions_count": len(all_suggestions),
                "conflicts_count": len(conflicts),
                "timestamp": datetime.now().isoformat()
            }]
        }
        
        return round_result

    def _collect_stakeholder_feedback(
        self, 
        curriculum: Dict[str, Any], 
        target_positions: List[str]
    ) -> Dict[str, List[Dict[str, Any]]]:
        """æ”¶é›†å„åˆ©ç›Šç›¸å…³è€…çš„åé¦ˆ"""
        print("ğŸ‘¥ æ”¶é›†åˆ©ç›Šç›¸å…³è€…åé¦ˆ...")
        
        feedback = {}
        
        for agent_type, agent in self.stakeholder_agents.items():
            try:
                print(f"  ğŸ¤– {agent.agent_name} æ­£åœ¨åˆ†æ...")
                
                # æ ¹æ®æ™ºèƒ½ä½“ç±»å‹ä¼ é€’ä¸åŒå‚æ•°
                if agent_type in ["hr_recruiter", "industry_expert"]:
                    result = agent.analyze(curriculum, target_positions=target_positions)
                else:
                    result = agent.analyze(curriculum)
                
                suggestions = result.get("suggestions", [])
                feedback[agent_type] = suggestions
                
                print(f"  âœ… {agent.agent_name} å®Œæˆï¼Œæå‡º {len(suggestions)} ä¸ªå»ºè®®")
                
            except Exception as e:
                print(f"  âŒ {agent.agent_name} åˆ†æå¤±è´¥: {str(e)}")
                feedback[agent_type] = []
        
        return feedback

    def _mediate_conflicts(
        self, 
        conflicts: List[Dict[str, Any]], 
        suggestions: List[Dict[str, Any]]
    ) -> List[Dict[str, Any]]:
        """è°ƒè§£å†²çªï¼ˆç®€åŒ–å®ç°ï¼‰"""
        print(f"âš–ï¸ è°ƒè§£ {len(conflicts)} ä¸ªå†²çª...")
        
        mediated_solutions = []
        
        for conflict in conflicts:
            # ç®€åŒ–çš„è°ƒè§£é€»è¾‘
            solution = {
                "solution_id": f"sol_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
                "resolved_conflicts": [conflict["conflict_id"]],
                "compromise_suggestions": conflict["involved_suggestions"],
                "implementation_plan": "ç»¼åˆè€ƒè™‘å„æ–¹æ„è§ï¼Œå¯»æ±‚å¹³è¡¡æ–¹æ¡ˆ",
                "stakeholder_acceptance": {
                    "academic_affairs": 0.8,
                    "hr_recruiter": 0.7,
                    "industry_expert": 0.8,
                    "student_representative": 0.6,
                    "faculty_representative": 0.7
                },
                "final_decision": "é‡‡ç”¨å¦¥åæ–¹æ¡ˆ"
            }
            mediated_solutions.append(solution)
        
        print(f"âœ… ç”Ÿæˆ {len(mediated_solutions)} ä¸ªè°ƒè§£æ–¹æ¡ˆ")
        return mediated_solutions

    def _apply_optimizations(
        self, 
        current_curriculum: Dict[str, Any], 
        solutions: List[Dict[str, Any]]
    ) -> Dict[str, Any]:
        """åº”ç”¨ä¼˜åŒ–æ–¹æ¡ˆï¼ˆç®€åŒ–å®ç°ï¼‰"""
        print("ğŸ”§ åº”ç”¨ä¼˜åŒ–æ–¹æ¡ˆ...")
        
        # ç®€åŒ–å®ç°ï¼šæš‚æ—¶è¿”å›åŸè¯¾ç¨‹ï¼Œåç»­å¯ä»¥æ ¹æ®è°ƒè§£æ–¹æ¡ˆå®é™…ä¿®æ”¹
        optimized_curriculum = current_curriculum.copy()
        
        # è¿™é‡Œåº”è¯¥æ ¹æ®è°ƒè§£æ–¹æ¡ˆå®é™…ä¿®æ”¹åŸ¹å…»æ–¹æ¡ˆ
        # ä¾‹å¦‚ï¼šæ·»åŠ /åˆ é™¤è¯¾ç¨‹ã€è°ƒæ•´å­¦åˆ†ã€ä¿®æ”¹å®è·µç¯èŠ‚ç­‰
        
        print("âœ… ä¼˜åŒ–æ–¹æ¡ˆåº”ç”¨å®Œæˆ")
        return optimized_curriculum

    def _evaluate_stakeholder_satisfaction(
        self, 
        stakeholder_suggestions: Dict[str, List[Dict[str, Any]]]
    ) -> Dict[str, float]:
        """è¯„ä¼°åˆ©ç›Šç›¸å…³è€…æ»¡æ„åº¦"""
        satisfaction = {}
        
        for agent_type, suggestions in stakeholder_suggestions.items():
            # ç®€åŒ–é€»è¾‘ï¼šæ ¹æ®å»ºè®®æ•°é‡å’Œä¼˜å…ˆçº§è¯„ä¼°æ»¡æ„åº¦
            if not suggestions:
                satisfaction[agent_type] = 0.5  # ä¸­æ€§æ»¡æ„åº¦
            else:
                avg_priority = sum(s.get("priority", 3) for s in suggestions) / len(suggestions)
                satisfaction[agent_type] = min(1.0, avg_priority / 5.0 + 0.3)
        
        return satisfaction

# æ¨¡æ‹Ÿæ™ºèƒ½ä½“ç±»ï¼ˆç”¨äºæµ‹è¯•ï¼‰
class MockAgent:
    """æ¨¡æ‹Ÿæ™ºèƒ½ä½“"""
    
    def __init__(self, agent_name: str, agent_type: str):
        self.agent_name = agent_name
        self.agent_type = agent_type
    
    def analyze(self, curriculum: Dict[str, Any], **kwargs) -> Dict[str, Any]:
        """æ¨¡æ‹Ÿåˆ†æ"""
        return {
            "suggestions": [
                {
                    "suggestion_id": f"mock_{self.agent_type}_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
                    "agent_type": self.agent_type,
                    "agent_name": self.agent_name,
                    "suggestion_type": "modify",
                    "target_component": "course",
                    "detailed_suggestion": f"{self.agent_name}çš„æ¨¡æ‹Ÿå»ºè®®",
                    "justification": "æ¨¡æ‹Ÿç†ç”±",
                    "priority": 3,
                    "feasibility": 0.8,
                    "expected_benefit": "æ¨¡æ‹Ÿæ”¶ç›Š",
                    "potential_risks": [],
                    "timestamp": datetime.now().isoformat()
                }
            ]
        } 